{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "* Part 1 is to update the 'parcels_geography.csv' file with the new zoningmods and nodev attributes\n",
    "* Part 2 is to generate geospacial files to use in GIS. The output file dissolves parcels on 'pba50zoningmodcat', and contains \"parcel count\" and \"total acres\" for each dissolved geometry. The script enables two approaches for dissolving: \n",
    "    * 1) Load the 'UrbanSim_input_Zoning\\outputs\\parcel_zoningmods.shp' into ArcGIS and dissolve.\n",
    "    * 2) Dissolve in geopands and then export. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import fiona\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv('USERNAME')=='ywang':\n",
    "    folder      = 'C:\\\\Users\\\\ywang\\\\Documents\\\\Files_for_Py\\\\UrbanSim_input_Zoning'\n",
    "    input_dir   = os.path.join(folder, 'inputs')\n",
    "    output_dir  = os.path.join(folder, 'outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f8c1dd2958e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mjuris_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\jurisId.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpg_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\07_11_2019_parcels_geography.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpba50_att_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\p10_pba50_attr_20200416.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mp10_geo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\p10_geo_shp.shp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m     \"\"\"\n\u001b[0;32m    544\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Input\n",
    "juris_raw = pd.read_csv(input_dir + '\\\\jurisId.csv')\n",
    "pg_old = pd.read_csv(input_dir + '\\\\07_11_2019_parcels_geography.csv')\n",
    "pba50_att_raw = pd.read_csv(input_dir + '\\\\p10_pba50_attr_20200416.csv')\n",
    "p10_geo = gpd.read_file(input_dir + '\\\\p10_geo_shp.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update 'parcels_geography.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pba50_att = pba50_att_raw[['geom_id_s','pda_id', 'tpp_id', 'exp_id', 'exp_score', 'opp_id', 'zoningmodcat', \n",
    "                           'perffoot', 'perfarea', 'mapshell', 'tpa_id', 'perfarea2', 'alt_zoning', 'zonetype', 'pubopp_id', \n",
    "                           'puboppuse', 'juris_id', 'juris','hra_id', 'trich_id', 'cat_id', 'chcat', 'zoninghzcat', \n",
    "                           'gg_id', 'tra_id', 'sesit_id', 'ppa_id', 'exp2020_id', 'pba50chcat', 'exsfd_id', 'chcatwsfd', \n",
    "                           'pba50zoningmodcat', 'nodev']]\n",
    "pg_temp = pg_old[['Unnamed: 0','geom_id','urbanized']]\n",
    "juris = juris_raw[['jurisdiction_id','juris_id']]\n",
    "p10_geo.PARCEL_ID = p10_geo.PARCEL_ID.apply(lambda x: int(x))\n",
    "p10_geo.geom_id_s = p10_geo.geom_id_s.apply(lambda x: int(x))\n",
    "\n",
    "pg = pg_temp.merge(pba50_att, left_on = 'geom_id', right_on = 'geom_id_s', how = 'left').merge(\n",
    "    juris, on = 'juris_id', how = 'left').merge(p10_geo, on = 'geom_id_s', how = 'left')\n",
    "\n",
    "# check missing pba50zoningmod\n",
    "print(pg.loc[pg.pba50zoningmodcat.isnull()].shape[0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcel attribute:\n",
    "p_att = ['PARCEL_ID','geom_id','jurisdiction_id','juris_id','juris','ACRES']\n",
    "\n",
    "# PBA40 fields:\n",
    "pba40_att = ['pda_id', 'tpp_id', 'exp_id', 'opp_id', 'zoningmodcat', 'perffoot', 'perfarea', 'urbanized']\n",
    "\n",
    "# Horizon fields:\n",
    "hor_att = ['hra_id', 'trich_id', 'cat_id', 'zoninghzcat']\n",
    "\n",
    "# PBA50 fields:\n",
    "pba50_att = ['gg_id', 'tra_id', 'sesit_id', 'ppa_id', 'exp2020_id', 'exsfd_id', 'pba50zoningmodcat', 'nodev','pba50chcat']\n",
    "\n",
    "# today's date in output file name:\n",
    "today = datetime.today().strftime('%Y_%m_%d')\n",
    "\n",
    "# export\n",
    "pg_csv_all = pg[p_att + pba40_att + hor_att + pba50_att]\n",
    "pg_csv_all.to_csv(output_dir + '\\\\'+today+'_parcels_geography.csv')\n",
    "\n",
    "pg_csv = pg[p_att + pba50_att]\n",
    "pg_csv.to_csv(output_dir + '\\\\'+today+'_parcels_geography_pba50_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 'parcel_zoningmods.shp' for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select required fields\n",
    "pg_geo = gpd.GeoDataFrame(pg[p_att + pba50_att + ['geometry']], geometry='geometry')\n",
    "pg_geo[['ACRES']] = pg_geo[['ACRES']].fillna(value=0)\n",
    "for i in ['gg_id', 'tra_id', 'sesit_id', 'ppa_id', 'exp2020_id', 'exsfd_id']:\n",
    "    pg_geo[[i]] = pg_geo[[i]].fillna(value= 'NA')\n",
    "pg_geo = pg_geo.where(pd.notnull(pg_geo), None)\n",
    "pg_geo.to_file(output_dir + '\\\\'+today+'_parcel_zoningmods.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for_join = pg[['pba50zoningmodcat','pba50chcat']].drop_duplicates()\n",
    "print(for_join.shape)\n",
    "for_join.to_csv(output_dir + '\\\\'+today+'zoningmods_for_join.csv')\n",
    "\n",
    "stats = pg_geo[['PARCEL_ID','ACRES','pba50zoningmodcat']].groupby(['pba50zoningmodcat']).agg({'PARCEL_ID':'count', 'ACRES': 'sum'}).reset_index()\n",
    "stats = stats.merge(for_join, on = 'pba50zoningmodcat', how = 'left')\n",
    "stats.columns = ['pba50zoningmodcat', 'parcel_count','acres','pba50chcat']\n",
    "stats_nonZero = stats.query('parcel_count > 0 & acres > 0')\n",
    "print(stats_nonZero.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping file\n",
    "\"\"\"\n",
    "pg_geo['modTemp'] = pg_geo[['gg_id', 'tra_id', 'sesit_id', 'ppa_id']].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "gdf = gpd.GeoDataFrame(pg_geo[['PARCEL_ID','modTemp','geometry']], geometry='geometry')\n",
    "print(gdf.shape)\n",
    "gdf2 = gdf.loc[gdf.geometry.notnull(),:]\n",
    "print(gdf2.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dissolve by pba50zoningmodca\n",
    "\"\"\"\n",
    "gdf2['geometry'] = gdf2.buffer(0.01)\n",
    "try:\n",
    "    zoningmod_dis = gdf2.dissolve(by='modTemp',as_index=False)\n",
    "except:\n",
    "    print('error: ', gdf2.modTemp)\n",
    "\n",
    "display(zoningmod_dis.head())\n",
    "\n",
    "df = pd.DataFrame(zoningmod_dis, copy=True)\n",
    "df_split = pd.concat([df['modTemp'].str.split('_', expand=True), df['geometry'],df['PARCEL_ID']], axis=1)\n",
    "display(df_split.head())\n",
    "df_split.columns = ['juris_id', 'gg_id', 'tra_id', 'sesit_id', 'ppa_id', 'exp2020_id', 'exsfd_id', 'chcatwsfd','NA','geometry','PARCEL_ID']\n",
    "df_split = df_split.merge(juris_name[['jurisdiction','juris']], left_on = 'juris_id', right_on = 'juris',how = 'left')\n",
    "df_split.drop(columns = ['juris','juris_id'], inplace = True)\n",
    "dissolved = gpd.GeoDataFrame(df_split, geometry='geometry')\n",
    "dissolved.to_file(output_dir + '\\\\pba50_zoningmods_diss.shp')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
